# 寻参函数

### 作者：ShuHang2
[![build](https://github.com/Anduin2017/HowToCook/actions/workflows/build.yml/badge.svg)](https://github.com/ShuHang2/ShuHang2.github.io)

# [返回目录](LightGBM回归模型.md)

通过随机算法，寻找LightGBM参数

## 预处理

预处理只需要和模型预测的预处理方式相同

```python
from sklearn.preprocessing import OrdinalEncoder
import pandas as pd
import numpy as np

all = pd.read_csv("./data/train.csv")
all = all.dropna(subset=["RainTomorrow"])

columns_miss_object = ["RainToday", "RainTomorrow"]

for column in columns_miss_object:
    all[column] = all[column].ffill().bfill()

cat_features = [
    "Date",
    "Location",
    "WindGustDir",
    "WindDir9am",
    "WindDir3pm",
    "RainToday",
    "RainTomorrow",
    "Evaporation",
    "Sunshine",
    "Cloud9am",
    "Cloud3pm",
]
ordinal_encoder = OrdinalEncoder(
    dtype=np.int32,
    handle_unknown="use_encoded_value",
    unknown_value=-1,
    encoded_missing_value=-1,
).set_output(transform="pandas")

all[cat_features] = ordinal_encoder.fit_transform(all[cat_features])
X = all.drop(columns=["RainTomorrow"])
y = all["RainTomorrow"]
```

## 数据集分割

由于测试集不含目标，因此，我们需要将训练集划分为有目标的训练集和测试集

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

## 随机查找参数

也可以使用网格查找、朴素贝叶斯查找

```python
import xgboost as xgb
from sklearn.model_selection import RandomizedSearchCV

param = {
    "learning_rate": np.random.uniform(0.01, 0.1, size=10),
    "reg_alpha": np.random.uniform(0.5, 1, size=10),
    "reg_lambda": np.random.uniform(0.1, 0.2, size=10),
    "n_estimators": np.random.randint(200, 400, size=10),
    "subsample": np.random.uniform(0.6, 0.8, size=10),
    "colsample_bytree": np.random.uniform(0.6, 1.0, size=10),
    "max_depth": np.random.randint(5, 10, size=10),
}

model = xgb.XGBRegressor(booster="gbtree", verbosity=0)
```

## 随机搜索最优参数

我们使用负均方根，作为参数选择的标准

```python
random_search = RandomizedSearchCV(
    model, param, n_iter=10, cv=5, scoring="neg_mean_squared_error"
)

random_search.fit(X_train, y_train)

print("Best Parameters:", random_search.best_params_)
best_score = random_search.best_score_
print("Best score (neg_root_mean_squared_error): ", best_score)
```

最后我们将训练出来的参数，填到LightGBM模型中
