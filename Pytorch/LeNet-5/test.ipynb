{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lib\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=269x215 at 0x246B039BB80>\n"
     ]
    }
   ],
   "source": [
    "image_path = \"./imgs/dog.png\"\n",
    "image = Image.open(image_path)\n",
    "print(image)\n",
    "# 将RGBBA转化为RGB类型\n",
    "image = image.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将图片转化为32*32，并且转化为张量\n",
    "\n",
    "3通道的32*32张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5608, 0.6824, 0.7569,  ..., 0.2627, 0.2745, 0.2745],\n",
      "         [0.7098, 0.8118, 0.8627,  ..., 0.2863, 0.2980, 0.2980],\n",
      "         [0.7843, 0.8667, 0.9137,  ..., 0.2902, 0.3020, 0.3059],\n",
      "         ...,\n",
      "         [0.5804, 0.6000, 0.6196,  ..., 0.5529, 0.5020, 0.4941],\n",
      "         [0.5059, 0.5412, 0.5804,  ..., 0.5255, 0.4745, 0.4588],\n",
      "         [0.4510, 0.4902, 0.5294,  ..., 0.4784, 0.4588, 0.4471]],\n",
      "\n",
      "        [[0.5725, 0.6941, 0.7725,  ..., 0.2431, 0.2549, 0.2549],\n",
      "         [0.7216, 0.8275, 0.8784,  ..., 0.2667, 0.2784, 0.2784],\n",
      "         [0.7961, 0.8824, 0.9255,  ..., 0.2706, 0.2824, 0.2863],\n",
      "         ...,\n",
      "         [0.5804, 0.6118, 0.6314,  ..., 0.4784, 0.4549, 0.4431],\n",
      "         [0.5098, 0.5529, 0.5922,  ..., 0.4627, 0.4392, 0.4235],\n",
      "         [0.4471, 0.4941, 0.5373,  ..., 0.4392, 0.4275, 0.4196]],\n",
      "\n",
      "        [[0.6275, 0.7647, 0.8471,  ..., 0.1725, 0.1804, 0.1804],\n",
      "         [0.7843, 0.8902, 0.9373,  ..., 0.1922, 0.2039, 0.2000],\n",
      "         [0.8706, 0.9412, 0.9725,  ..., 0.1922, 0.2039, 0.1961],\n",
      "         ...,\n",
      "         [0.6000, 0.6431, 0.6706,  ..., 0.3333, 0.3020, 0.2902],\n",
      "         [0.5137, 0.5725, 0.6235,  ..., 0.3176, 0.2902, 0.2745],\n",
      "         [0.4549, 0.5137, 0.5725,  ..., 0.3020, 0.2863, 0.2902]]])\n",
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.Resize((32, 32)), torchvision.transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "image = transform(image)\n",
    "print(image)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将分类结果转化为对应类型\n",
    "target = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=1024, out_features=64, bias=True)\n",
      "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[-0.0763, -1.9282,  2.8824,  1.0389,  0.2248,  4.0342, -4.1459,  0.7281,\n",
      "         -3.6155, -0.9722]])\n",
      "tensor([5])\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"./model/model_9.pth\", map_location=torch.device(\"cpu\"))\n",
    "print(model)\n",
    "\n",
    "image = torch.reshape(image, (1, 3, 32, 32))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "print(output)\n",
    "\n",
    "print(output.argmax(1))\n",
    "\n",
    "print(target[output.argmax(1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
